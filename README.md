The pipeline is built to:

Ingest data from the GitHub API using Apache Airflow and Apache Kafka.

Process data in real-time using Apache Spark for streaming and analysis.

Store processed data in Apache Cassandra for efficient querying and retrieval.

Containerize the pipeline using Docker for easy deployment and scalability.
